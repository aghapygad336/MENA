{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gtd_happiness.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aghapygad336/MENA/blob/master/gtd_happiness.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdHwAEME_gGk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.ensemble import ExtraTreesClassifier, AdaBoostRegressor\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import csv\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from openpyxl.utils import dataframe\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "import seaborn as sns\n",
        "from math import sqrt\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "from matplotlib import colors as cs\n",
        "from scipy.stats import pearsonr\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import scale\n",
        "from sklearn import preprocessing, metrics\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn import tree\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import make_scorer, precision_score, recall_score, confusion_matrix\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5VDozn1zbJ9",
        "colab_type": "code",
        "outputId": "d45d6ded-2f0b-4da0-f554-53f11b0d55b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcKYyxdelNPQ",
        "colab_type": "text"
      },
      "source": [
        "**The Global Terrorism Database (GTD)** \n",
        "documents more than 190,000 international and domestic terrorist attacks that occurred worldwide since 1970. With details on various dimensions of each attack, the GTD familiarizes analysts, policymakers, scholars, and journalists with patterns of terrorism. The GTD defines terrorist attacks as: Acts by non-state actors involving the threatened or actual use of illegal force or violence to attain a political, economic, religious, or social goal through fear, coercion, or intimidation. Data collection is ongoing and updates are published annually at."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKXUR64u0CFS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "data2015 = pd.read_csv('/content/drive/My Drive/MENA/2015.csv',encoding = \"ISO-8859-1\", engine = 'python')\n",
        "data2016 = pd.read_csv('/content/drive/My Drive/MENA/2016.csv',encoding = \"ISO-8859-1\", engine = 'python')\n",
        "data2017 = pd.read_csv('/content/drive/My Drive/MENA/2017.csv',encoding = \"ISO-8859-1\", engine = 'python')\n",
        "happiness = data2015.append(data2016.append(data2017,sort=True),sort= True)\n",
        "gtd = pd.read_csv('/content/drive/My Drive/MENA/golbal.csv',encoding = \"ISO-8859-1\", engine = 'python', usecols=[1,2,3,8,10,19,20,21,22,26,27,29,35,41,71,84,100,101,103,58])\n",
        "gtd = gtd[(gtd['region_txt'] =='Middle East & North Africa') & (gtd['iyear'] > 2000)]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOeLwyrSlt5V",
        "colab_type": "text"
      },
      "source": [
        "**Missing values** are representative of the messiness of real world data. There can be a multitude of reasons why they occur — ranging from human errors during data entry, incorrect sensor readings, to software bugs in the data processing pipeline.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQ-hLDHynwqq",
        "colab_type": "text"
      },
      "source": [
        "**Categorial** Let’s start with the most simple thing you can do: removal. As mentioned before, while this is a quick solution, and might work in some cases when the proportion of missing values is relatively low (<10%), most of the time it will make you lose a ton of data. Imagine that just because of missing values in one of your features you have to drop the whole observation, even if the rest of the features are perfectly filled and informative!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZvUPchpn6I1",
        "colab_type": "text"
      },
      "source": [
        "**Numerical NaNs** A standard and often very good approach is to replace the missing values with mean, median or mode. For numerical values you should go with mean, and if there are some outliers try median (since it is much less sensitive to them)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-V8yYdK0w3Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# gtd missing values\n",
        "numeric_ = gtd._get_numeric_data()\n",
        "cat = gtd.select_dtypes(include='object')\n",
        "mean_nan = numeric_.fillna(numeric_.mean()).dropna(axis=1, how='all')\n",
        "cat_nan = cat.loc[:, cat.isnull().mean() <0.25]\n",
        "gtd = mean_nan.join(cat_nan)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMWTFllUBOxT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "numeric_ = happiness._get_numeric_data()\n",
        "cat = happiness.select_dtypes(include='object')\n",
        "mean_nan = numeric_.fillna(numeric_.mean()).dropna(axis=1, how='all')\n",
        "cat_nan = cat.loc[:, cat.isnull().mean() <0.25]\n",
        "happiness = mean_nan.join(cat_nan)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-ROtG_qoDsi",
        "colab_type": "text"
      },
      "source": [
        "Better encoding of categorical data can mean better model performance. In this series I’ll introduce you to a wide range of encoding options .\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5YcsrWAfb1X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encoding(dfData):    \n",
        "    df = dfData.copy().select_dtypes(include='object')\n",
        "    # print(df.columns)\n",
        "    rows,cols = dfData.shape\n",
        "    encodings = {}\n",
        "    for col in df.columns:\n",
        "        Region_nums = []\n",
        "        Region_nums = df[col].unique()\n",
        "        Region_nums = { Region_nums[i]: i for i in range(len(Region_nums)) }\n",
        "        encodings.update({col:Region_nums})\n",
        "        dfData[col].replace(Region_nums, inplace=True)\n",
        "    return dfData,encodings\n",
        "\n",
        "def get_by_value(dic,value):\n",
        "    for key, val in dic.items():\n",
        "        if val == value :\n",
        "            return key    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LeKEcq1fz8N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gtd, gtd_encodings = encoding(gtd)\n",
        "happiness, happiness_encodings = encoding(happiness)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9laodI92qfJO",
        "colab_type": "text"
      },
      "source": [
        "Having about 600 terrorist group name (class labels), with some groups with less\n",
        "than 10 attacks which may cause misleading results. You are required to reduce the\n",
        "number of class labels to the 5 groups with max number of attacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HK6ODYye9Jdo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "top_5 = gtd['gname'].value_counts()[1:6]\n",
        "top_5 = [203,27,107,67,58]\n",
        "gtd = gtd[gtd['gname'].isin(top_5)]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioH0Hfl4PXbb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "combinedData=pd.merge(gtd, happiness, left_on='country_txt', right_on='Country')\n",
        "happiness, happiness_encodings = encoding(happiness)\n",
        "combinedDataE, combinedData_encodings = encoding(combinedData)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTkfx5VXAPRV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def SplitTrainTes(dataSet):\n",
        "    train_dataSet=dataSet[(dataSet['iyear'] >=2000) & (dataSet['iyear'] <= 2016)]\n",
        "    test_dataSet=dataSet[dataSet['iyear'] ==2017]\n",
        "    return train_dataSet,test_dataSet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6A8C6F4gqiYd",
        "colab_type": "text"
      },
      "source": [
        "**Training and Testing**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "a. You are required to use the tuples of years from [2000. 2016] as training set\n",
        "b. Tuples of year 2017 will be used as testing set.\n",
        "c. We have 2 approaches in this assignment\n",
        "i. Train and test using features of GTD only.\n",
        "ii. Train and test using features of GTD and WHR combined."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5jPLibb8JAP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_GTD,test_GTD=SplitTrainTes(gtd)\n",
        "train_Combined,test_Combined=SplitTrainTes(combinedData)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVogRdaoDDFf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def splitX_SplitY(trainD,testD):\n",
        "    x_train = trainD.drop(\"gname\", axis=1)\n",
        "    y_train = trainD[\"gname\"]\n",
        "    x_test = testD.drop(\"gname\", axis=1)\n",
        "    y_test = testD[\"gname\"]\n",
        "    return x_train,y_train,x_test,y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayrOo3y6-nlL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_trainGTD,y_trainGTD,x_testGTD,y_testGTD=splitX_SplitY(train_GTD,test_GTD)\n",
        "x_trainCombined,y_trainCombined,x_testCombined,y_testCombined=splitX_SplitY(train_Combined,test_Combined)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kn7Gay4drqyV",
        "colab_type": "text"
      },
      "source": [
        "**The F measure** \n",
        "\n",
        "---\n",
        "(F1 score or F score) is a measure of a test's accuracy of   **Classifier Models** and is defined as the weighted harmonic mean of the precision and recall of the test. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMGtP-5lEjKY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "def Fmeasure(estimator,x_train,y_train,x_test,y_test):\n",
        "    y_pred_train = estimator.predict(x_train)\n",
        "    y_pred_test = estimator.predict(x_test)\n",
        "    accuracyF_Train=accuracy_score(y_train, y_pred_train)\n",
        "    accuracyF_Test= accuracy_score(y_test, y_pred_test)\n",
        "    print('Train Set Accuracy : ', accuracyF_Train)\n",
        "    print('Train Set Precision : ', precision_score(y_train, y_pred_train, average='micro'))\n",
        "    print('Train Set Recall : ', recall_score(y_train, y_pred_train, average='micro'))\n",
        "    print('Train F-Score for each class : ', f1_score(y_train, y_pred_train, average='micro'))\n",
        "    print('Train Mean F-Score for both classes : ', f1_score(y_train, y_pred_train, average='micro'))\n",
        "\n",
        "    print('----------------------------------------------------------------------')\n",
        "    print('Test Set Accuracy : ', accuracy_score(y_test, y_pred_test))\n",
        "    print('Test Set Precision : ', precision_score(y_test, y_pred_test, average='micro'))\n",
        "    print('Test Set Recall : ', recall_score(y_test, y_pred_test, average='micro'))\n",
        "    print('Test F-Score for each class : ', f1_score(y_test, y_pred_test, average='micro'))\n",
        "    print('Test Mean F-Score for both classes : ', f1_score(y_test, y_pred_test, average='micro'))\n",
        "\n",
        "    print('----------------------------------------------------------------------')\n",
        "    return accuracyF_Train,accuracyF_Test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJKQmfXY-kWU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def kNearestNeighborsFunction(x_train,y_train,x_test,y_test):\n",
        "    neighbors = list(range(1, 30, 2))\n",
        "    # empty list that will hold cv scores\n",
        "    cv_scores = []\n",
        "    # perform 10-fold cross validation\n",
        "    for k in neighbors:\n",
        "        knn = KNeighborsClassifier(n_neighbors=k)\n",
        "        scores = cross_val_score(knn, x_train, y_train, cv=10, scoring='accuracy')\n",
        "        cv_scores.append(scores.mean())\n",
        "\n",
        "    mse = [1 - x for x in cv_scores]\n",
        "    optimal_k = neighbors[mse.index(min(mse))]\n",
        "    n=optimal_k\n",
        "    print('Best N found at ' , n)\n",
        "    knn = KNeighborsClassifier(n_neighbors=n)\n",
        "    knn.fit(x_train,y_train)\n",
        "    testAccKNN,trainAccKNN=Fmeasure(knn,x_train,y_train,x_test,y_test)\n",
        "    return testAccKNN,trainAccKNN\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmyhYQqBwmxI",
        "colab_type": "text"
      },
      "source": [
        "**The k-nearest neighbors (KNN)** algorithm is a simple, easy-to-implement supervised machine learning algorithm that can be used to solve both classification and regression problems The KNN algorithm assumes that similar things exist in close proximity. In other words, similar things are near to each other.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdQfscD1Dcio",
        "colab_type": "code",
        "outputId": "4e9be5bc-0cb9-4ee9-bb64-ad7596a028d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        }
      },
      "source": [
        "knnAccuracytestGTD,KnnnAccuracytrainGTD=kNearestNeighborsFunction(x_trainGTD,y_trainGTD,x_testGTD,y_testGTD)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best N found at  3\n",
            "Train Set Accuracy :  0.9203720219136196\n",
            "Train Set Precision :  0.9203720219136196\n",
            "Train Set Recall :  0.9203720219136196\n",
            "Train F-Score for each class :  0.9203720219136196\n",
            "Train Mean F-Score for both classes :  0.9203720219136196\n",
            "----------------------------------------------------------------------\n",
            "Test Set Accuracy :  0.8993329290479078\n",
            "Test Set Precision :  0.8993329290479078\n",
            "Test Set Recall :  0.8993329290479078\n",
            "Test F-Score for each class :  0.8993329290479077\n",
            "Test Mean F-Score for both classes :  0.8993329290479077\n",
            "----------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-AcAuWQmc85",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "outputId": "58cd7ab8-4c53-47d4-aca0-951267942b68"
      },
      "source": [
        "knnAccuracytestCombined,KnnnAccuracytrainCombined=kNearestNeighborsFunction(x_trainCombined,y_trainCombined,x_testCombined,y_testCombined)\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best N found at  21\n",
            "Train Set Accuracy :  0.9180787361447318\n",
            "Train Set Precision :  0.9180787361447318\n",
            "Train Set Recall :  0.9180787361447318\n",
            "Train F-Score for each class :  0.9180787361447318\n",
            "Train Mean F-Score for both classes :  0.9180787361447318\n",
            "----------------------------------------------------------------------\n",
            "Test Set Accuracy :  0.9145610134087999\n",
            "Test Set Precision :  0.9145610134087999\n",
            "Test Set Recall :  0.9145610134087999\n",
            "Test F-Score for each class :  0.9145610134088\n",
            "Test Mean F-Score for both classes :  0.9145610134088\n",
            "----------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1CJu9vqw3B6",
        "colab_type": "text"
      },
      "source": [
        "**Decision Trees** A tree has many analogies in real life, and turns out that it has influenced a wide area of machine learning, covering both classification and regression. In decision analysis, a decision tree can be used to visually and explicitly represent decisions and decision making. As the name goes, it uses a tree-like model of decisions. Though a commonly used tool in data mining for deriving a strategy to reach a particular goal, its also widely used in machine learning, which will be the main focus of this article.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BThSmWAL-tu6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def DT (x_train,y_train,x_test,y_test):\n",
        "    ct_gini = DecisionTreeClassifier()\n",
        "    ct_entropy = DecisionTreeClassifier(criterion=\"entropy\")\n",
        "    ct_gini = ct_gini.fit(x_train, y_train)\n",
        "    ct_entropy = ct_entropy.fit(x_train, y_train)\n",
        "    testAccDT_Entropy,trainAccDT_Entropy=Fmeasure(ct_entropy,x_train,y_train,x_test,y_test)\n",
        "    testAccDT_Gini,trainAccDT_Gini=Fmeasure(ct_gini,x_train,y_train,x_test,y_test)\n",
        "    return testAccDT_Entropy,trainAccDT_Entropy,testAccDT_Gini,trainAccDT_Gini"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zuya-4z-Du7E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "outputId": "0b640291-0fac-42a7-f2c5-c9908716993e"
      },
      "source": [
        "testAccgtdDT_Entropy,trainAccgtdDT_Entropy,testAccgtdDT_Gini,trainAccgtdDT_Gini=DT(x_trainGTD,y_trainGTD,x_testGTD,y_testGTD)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Set Accuracy :  0.9998725952350618\n",
            "Train Set Precision :  0.9998725952350618\n",
            "Train Set Recall :  0.9998725952350618\n",
            "Train F-Score for each class :  0.9998725952350618\n",
            "Train Mean F-Score for both classes :  0.9998725952350618\n",
            "----------------------------------------------------------------------\n",
            "Test Set Accuracy :  0.968465736810188\n",
            "Test Set Precision :  0.968465736810188\n",
            "Test Set Recall :  0.968465736810188\n",
            "Test F-Score for each class :  0.968465736810188\n",
            "Test Mean F-Score for both classes :  0.968465736810188\n",
            "----------------------------------------------------------------------\n",
            "Train Set Accuracy :  0.9998725952350618\n",
            "Train Set Precision :  0.9998725952350618\n",
            "Train Set Recall :  0.9998725952350618\n",
            "Train F-Score for each class :  0.9998725952350618\n",
            "Train Mean F-Score for both classes :  0.9998725952350618\n",
            "----------------------------------------------------------------------\n",
            "Test Set Accuracy :  0.9654335961188599\n",
            "Test Set Precision :  0.9654335961188599\n",
            "Test Set Recall :  0.9654335961188599\n",
            "Test F-Score for each class :  0.9654335961188599\n",
            "Test Mean F-Score for both classes :  0.9654335961188599\n",
            "----------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZZXDymbdXJ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "testAccDTCombinedDT,trainAccDCombinedDT=DT(x_trainCombined,y_trainCombined,x_testCombined,y_testCombined)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YzYg4QDxPeR",
        "colab_type": "text"
      },
      "source": [
        "Classification and prediction are two the most important aspects of Machine Learning and Naive Bayes is a simple but surprisingly powerful algorithm for predictive modeling. \n",
        "Naive Bayes is among one of the simplest, but most powerful algorithms for classification based on Bayes' Theorem with an assumption of independence among predictors. The Naive Bayes model is easy to build and particularly useful for very large data sets. This part to this algorithm: **Naive Bayes**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7VLD1rP_RLc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def NB(x_train,y_train,x_test,y_test):\n",
        "    nb = GaussianNB()\n",
        "    nb = nb.fit(x_train, y_train)\n",
        "    testAccNB,trainAccNB=Fmeasure(nb,x_train,y_train,x_test,y_test)\n",
        "    return testAccNB,trainAccNB"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rexxtAV2ID4N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "05daaf24-544d-4d53-bbd5-f13c297b7ffb"
      },
      "source": [
        "testAccDTgtdNB,trainAccDgtdNB=NB(x_trainGTD,y_trainGTD,x_testGTD,y_testGTD)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Set Accuracy :  0.39482736654350875\n",
            "Train Set Precision :  0.39482736654350875\n",
            "Train Set Recall :  0.39482736654350875\n",
            "Train F-Score for each class :  0.39482736654350875\n",
            "Train Mean F-Score for both classes :  0.39482736654350875\n",
            "----------------------------------------------------------------------\n",
            "Test Set Accuracy :  0.39357186173438446\n",
            "Test Set Precision :  0.39357186173438446\n",
            "Test Set Recall :  0.39357186173438446\n",
            "Test F-Score for each class :  0.39357186173438446\n",
            "Test Mean F-Score for both classes :  0.39357186173438446\n",
            "----------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHnYlvnhdbd0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "testAccDTCombinedNB,trainAccDCombinedNB=NB(x_trainCombined,y_trainCombined,x_testCombined,y_testCombined)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knrjlH1wxwB4",
        "colab_type": "text"
      },
      "source": [
        "**Logistic Regression** is a ‘Statistical Learning’ technique categorized in ‘Supervised’ Machine Learning (ML) methods dedicated to ‘Classification’ tasks. It has gained a tremendous reputation for last two decades especially in financial sector due to its prominent ability of detecting defaulters. A general usage schema of…\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJroQvOH_-JA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def LR(x_train,y_train,x_test,y_test):\n",
        "    import warnings\n",
        "    warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "    grid = {\"C\": np.logspace(-3, 3, 7), \"penalty\": [\"l1\", \"l2\"]}  # l1 lasso l2 ridge\n",
        "    logreg = LogisticRegression()\n",
        "    logreg_cv = GridSearchCV(logreg, grid, cv=10)\n",
        "    logreg_cv.fit(x_train, y_train)\n",
        "    print(\"tuned hpyerparameters :(best parameters) \", logreg_cv.best_params_)\n",
        "    testAccLR,trainAccLR=Fmeasure(logreg_cv,x_train,y_train,x_test,y_test)\n",
        "    print(\"accuracy :\", logreg_cv.best_score_)\n",
        "    return testAccLR,trainAccLR"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcjlJjesfcyt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "outputId": "676e8357-3354-4f27-a2f2-f25bb77376ee"
      },
      "source": [
        "testAccLR_gtd,trainAccLR_gtd=LR(x_trainGTD,y_trainGTD,x_testGTD,y_testGTD)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tuned hpyerparameters :(best parameters)  {'C': 10.0, 'penalty': 'l1'}\n",
            "Train Set Accuracy :  0.7789527328322079\n",
            "Train Set Precision :  0.7789527328322079\n",
            "Train Set Recall :  0.7789527328322079\n",
            "Train F-Score for each class :  0.7789527328322079\n",
            "Train Mean F-Score for both classes :  0.7789527328322079\n",
            "----------------------------------------------------------------------\n",
            "Test Set Accuracy :  0.8993329290479078\n",
            "Test Set Precision :  0.8993329290479078\n",
            "Test Set Recall :  0.8993329290479078\n",
            "Test F-Score for each class :  0.8993329290479077\n",
            "Test Mean F-Score for both classes :  0.8993329290479077\n",
            "----------------------------------------------------------------------\n",
            "accuracy : 0.7677411135176455\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IbmPxNOAFvg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def AB(x_train,y_train,x_test,y_test):\n",
        "    import warnings\n",
        "    warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "    param_grid = {\n",
        "        'learning_rate': [.1, .2, .3, .4, .5],\n",
        "\n",
        "        'n_estimators': [50, 100, 150, 200, 250]\n",
        "    }\n",
        "\n",
        "    classifier = AdaBoostClassifier()\n",
        "    grid_Search = GridSearchCV(classifier, param_grid=param_grid)\n",
        "    kk = grid_Search.fit(x_train, y_train)\n",
        "    testAccAB,trainAccAB= Fmeasure(kk,x_train,y_train,x_test,y_test)\n",
        "    return testAccAB,trainAccAB"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPpRAKjhGrTJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "ebc914da-ef79-4585-c673-101040b3c05b"
      },
      "source": [
        "testAccAB_gtd,trainAccAB_gtd=AB(x_trainGTD,y_trainGTD,x_testGTD,y_testGTD)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Set Accuracy :  0.909032997834119\n",
            "Train Set Precision :  0.909032997834119\n",
            "Train Set Recall :  0.909032997834119\n",
            "Train F-Score for each class :  0.909032997834119\n",
            "Train Mean F-Score for both classes :  0.909032997834119\n",
            "----------------------------------------------------------------------\n",
            "Test Set Accuracy :  0.9563371740448757\n",
            "Test Set Precision :  0.9563371740448757\n",
            "Test Set Recall :  0.9563371740448757\n",
            "Test F-Score for each class :  0.9563371740448757\n",
            "Test Mean F-Score for both classes :  0.9563371740448757\n",
            "----------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1Ve1RQmx8kg",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-m5B0xEeKZo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testAccAB_combined,trainAccAB_combined=AB(x_trainCombined,y_trainCombined,x_testCombined,y_testCombined)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09ila-EbAIRn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def SVM(x_train,y_train,x_test,y_test):\n",
        "    from sklearn.svm import SVC\n",
        "    svclassifier = SVC(kernel='poly', degree=8)\n",
        "    svclassifier.fit(x_train, y_train)\n",
        "    testAccAB_SVM,trainAccAB_SVM=Fmeasure(svclassifier,x_train,y_train,x_test,y_test)\n",
        "    return testAccAB_SVM,trainAccAB_SVM\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5R8AcIciQkAE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "1c5ce290-97a7-496a-e101-4ab80e72a900"
      },
      "source": [
        "testAccAB_gtd_SVM,trainAccAB_gtd_SVM=SVM(x_trainGTD,y_trainGTD,x_testGTD,y_testGTD)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Set Accuracy :  0.5441457510510893\n",
            "Train Set Precision :  0.5441457510510893\n",
            "Train Set Recall :  0.5441457510510893\n",
            "Train F-Score for each class :  0.5441457510510893\n",
            "Train Mean F-Score for both classes :  0.5441457510510893\n",
            "----------------------------------------------------------------------\n",
            "Test Set Accuracy :  0.7835051546391752\n",
            "Test Set Precision :  0.7835051546391752\n",
            "Test Set Recall :  0.7835051546391752\n",
            "Test F-Score for each class :  0.7835051546391752\n",
            "Test Mean F-Score for both classes :  0.7835051546391752\n",
            "----------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kS7IlH6znYUH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fScoreTest=[knnAccuracytestGTD,testAccgtdDT_Entropy,testAccgtdDT_Gini,testAccDTgtdNB,testAccLR_gtd,testAccAB_gtd,testAccAB_gtd_SVM]\n",
        "fScoreTrain=[KnnnAccuracytrainGTD,trainAccgtdDT_Entropy,trainAccgtdDT_Gini,trainAccDgtdNB,trainAccLR_gtd,trainAccAB_gtd,trainAccAB_gtd_SVM]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0d7Jj5Xl4er",
        "colab_type": "text"
      },
      "source": [
        "**Ploting**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLjwqabMl3nK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plotFmeasure(fScoreTrain,fScoreTest):\n",
        "    model_names = ['knn','Decision tree entropy','Decisiontree gini ','Naive Bayes','Logistic Regression','Adaboost','SVM']\n",
        "   \n",
        "    \n",
        "    \n",
        "    plt.figure()\n",
        "    train=plt.scatter(fScoreTrain,model_names,c='blue')\n",
        "    test=plt.scatter(fScoreTest,model_names,c='red')\n",
        "    plt.xlabel('Fmeasure')\n",
        "    plt.ylabel('Model ')\n",
        "    plt.legend((train,test),\n",
        "           ('Train','Test'),\n",
        "           scatterpoints=1,\n",
        "           loc='lower left',\n",
        "           ncol=3,\n",
        "           fontsize=8)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKHymcw7rwxq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "38f6c3d6-9f23-4ba5-ec98-84a8913fdf62"
      },
      "source": [
        "plotFmeasure(fScoreTrain,fScoreTest)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd4AAAEGCAYAAADL8/SBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nidfMzCxHTrxmZmY5+v+274LOyn7iSwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}